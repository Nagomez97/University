Respeustas Ej4:

4.1) Se utilizan 100000000 (10^8) rectángulos

4.2) La diferencia es que en pi_par1 escribimos directamente sobre el array sum, de manera que tenemos una zona de memoria compartida donde cada thread escribirá en una posición diferente.
Sin embargo, en pi_par4, declaramos una variable dentro del thread llamada priv_sum, escribimos sobre ella y luego la asignamos a la posición concreta de memoria.

4.3) Observamos que el resultado es el mismo. El rendimiento si que presenta algún cambio. Esto se puede deber a que acceder a una variable compartida es más lento que el acceso a una variable privada. Seguramente la variable compartida tenga que estar constantemente cambiando entre las cachés de nivel uno de los distintos cores, provocando una ralentización en la ejecución. (false sharing)

4.4) Podemos ver que el resultado sigue siendo el mismo. En cuanto al rendimiento vemos que pi_par2 tiene un rendimiento similar a pi_par1 y que pi_par3 se aproxima más a pi_par4. El resultado es el mismo, ya que al declarar sum como firstprivate en pi_par2, y ser sum un puntero, al modificar el contenido del mismo estaremos escribiendo en una posición de memoria, sin alterar la variable sum como tal. De este modo, al salir del pragma mantendremos la información guardada en la posición de memoria.
En el caso de pi_par3 se obtiene lo esperado, sum se declara de manera que el tamaño del array sea de numero de nucles x elementos que se transfieren por carga desde la cache de nivel 3. Por ello cuando accedemos a la posición numero de thread x elementos, accedemos a un único bloque de caché 3, por lo que no forzamos a que el bloque donde esta sum se tranfiera entre núcleos.

4.5) En este caso lo que hemos hecho es modificar la línea 32 de pi_par3 de manera que si el programa no recibe ningún argumento use el valor por defecto. Si recibe algún argumento, lo usará como padding. Pudiendo hacer el apartado con un script.
Podemos observar que si el padding insertado es menor que el padding habitual, obtenemos un resultado similar a pi_par1. Esto se debe a la misma razón: El abuso en los cambios del dato entre cachés. Ahora bien, para valores mayores o iguales al padding habitual obtenemos resultados muy similares entre sí, con una aceleración significativa y un tiempo de ejcución similar a pi_par4